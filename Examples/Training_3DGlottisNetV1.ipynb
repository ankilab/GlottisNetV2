{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f625741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "from GlottisNetV2.Utils.DataGeneratorV1_vids import DataGenerator\n",
    "from GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp, load_video_ap\n",
    "from GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "from GlottisNetV2.Models.GlottisNetV1 import glottisnetV1\n",
    "\n",
    "from GlottisNetV2.Utils.data import MAPE_V1\n",
    "from GlottisNetV2.Utils.data import mape_apV1\n",
    "from GlottisNetV2.Utils.data import mape_ppV1\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15672742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data set\n",
    "vid_training = r\"Set path to training videos\" # TODO\n",
    "\n",
    "N_train = 640\n",
    "\n",
    "# Set column names\n",
    "cols = ['z', 'path']\n",
    "\n",
    "# Create new pandas dataframe for image ids\n",
    "df_imgs_train = pd.DataFrame(columns=cols)\n",
    "df_segs_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Create video IDs for training data\n",
    "for i in tqdm(range(N_train)):\n",
    "    vpath = vid_training + \"\\\\\" + str(i) + \".mp4\"\n",
    "    \n",
    "    if os.path.exists(vpath):      \n",
    "        new_img = {'z': i, 'path': vid_training + r\"\\\\\" + str(i) + \".mp4\"}\n",
    "        new_seg = {'z': i, 'path': vid_training + r\"\\\\\" + str(i) + \"_mask.mp4\"}\n",
    "\n",
    "        df_imgs_train = df_imgs_train.append(new_img, ignore_index=True)\n",
    "        df_segs_train = df_segs_train.append(new_seg, ignore_index=True)  \n",
    "print('Created IDs for training images.')\n",
    "        \n",
    "# Save coordinates of anterior and posterior points in Pandas Dataframe\n",
    "cols = ['z', 'ap', 'pp']\n",
    "training_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(N_train)):    \n",
    "\n",
    "    # Load video path\n",
    "    vpath = vid_training + \"\\\\\" + str(i) + \".mp4\"\n",
    "\n",
    "    # If path exists, add video to dataframe\n",
    "    if os.path.exists(vpath):\n",
    "        path_vid = vid_training + \"\\\\\" + str(i) + \".points\"\n",
    "        ap_video = load_video_ap(path_vid, i)\n",
    "        training_data = training_data.append(ap_video, ignore_index=True)\n",
    "print('Loaded anterior and posterior points to dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training'''\n",
    "\n",
    "# Set random seed for reproducible training\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "rand=np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "\n",
    "# Set batch size, learning rate and epochs\n",
    "BATCH_SIZE = 8 # adjust for your graphics card\n",
    "LEARNING_RATE = 0.2e-3\n",
    "EPOCHS = 100\n",
    "TARGET_HEIGHT = 256\n",
    "TARGET_WIDTH = 128\n",
    "SHUFFLE = False\n",
    "AUGMENT = True\n",
    "RETURN_MAPS = False\n",
    "FILTERS = 64\n",
    "LAYERS = 4\n",
    "MODEL_PATH = r\"Set model path\" # TODO\n",
    "STEPS_PATH = r\"Set path to model checkpoints\" # TODO\n",
    "N_STEPS = 10 # Save every #N_STEPS epoch\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = glottisnetV1(filters = FILTERS, layers = LAYERS, input_size=(TARGET_HEIGHT, TARGET_WIDTH, 1))\n",
    "#model = load_model(r\"C:\\Users\\fa76xipu\\Models\\test\\glottisnetv1.h5\",  custom_objects={\"seg\": dice_loss}, compile=False)\n",
    "\n",
    "# Hard split of training and validation data \n",
    "train_vids, val_vids, train_segs, val_segs = train_test_split(df_imgs_train, df_segs_train,  test_size = 0.1, random_state = SEED)\n",
    "\n",
    "# Set column names\n",
    "cols = ['z', 'path', 'id']\n",
    "\n",
    "# Create new pandas dataframe for image ids\n",
    "train_vids_new = pd.DataFrame(columns=cols)\n",
    "val_vids_new = pd.DataFrame(columns=cols)\n",
    "train_segs_new = pd.DataFrame(columns=cols)\n",
    "val_segs_new = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Multiply number of videos for training and validation\n",
    "for i in range(len(train_vids)):\n",
    "    for j in range(10):           \n",
    "\n",
    "        nr = random.randint(0, 29) \n",
    "\n",
    "        new_img = {'z': train_vids.iloc[i]['z'] , 'path': train_vids.iloc[i]['path'], 'id': nr}\n",
    "        new_seg = {'z': train_segs.iloc[i]['z'] , 'path': train_segs.iloc[i]['path'], 'id': nr}\n",
    "\n",
    "        train_vids_new  = train_vids_new.append(new_img, ignore_index=True)\n",
    "        train_segs_new  = train_segs_new.append(new_seg, ignore_index=True)\n",
    "            \n",
    "            \n",
    "for i in range(len(val_vids)):\n",
    "    for j in range(10):      \n",
    "\n",
    "        nr= random.randint(0, 29)\n",
    "\n",
    "        new_img = {'z': val_vids.iloc[i]['z'] , 'path': val_vids.iloc[i]['path'], 'id': nr}\n",
    "        new_seg = {'z': val_segs.iloc[i]['z'] , 'path': val_segs.iloc[i]['path'], 'id': nr}\n",
    "\n",
    "        val_vids_new  = val_vids_new.append(new_img, ignore_index=True)\n",
    "        val_segs_new = val_segs_new.append(new_seg, ignore_index=True) \n",
    "            \n",
    "\n",
    "# Datagenerator --> Augmentation and Shuffle\n",
    "# Training data \n",
    "training_generator = DataGenerator(train_vids_new, train_segs_new, batch_size = BATCH_SIZE, target_height = TARGET_HEIGHT, \\\n",
    "                                   target_width = TARGET_WIDTH, shuffle = SHUFFLE, df_coordinates = training_data, \\\n",
    "                                   augment = AUGMENT)\n",
    "\n",
    "# Validation data\n",
    "validation_generator = DataGenerator(val_vids_new, val_segs_new, target_height = TARGET_HEIGHT, \\\n",
    "                                     target_width = TARGET_WIDTH, batch_size = BATCH_SIZE, shuffle = False, \\\n",
    "                                     df_coordinates = training_data, augment = False)  \n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE), \n",
    "              metrics={'seg': ['acc', iou_score], 'ap_pred': ['acc', MAPE_V1, mape_apV1, mape_ppV1]},\n",
    "              loss = {'ap_pred': 'mse', 'seg': dice_loss}, run_eagerly = True)\n",
    "\n",
    "\n",
    "# Train model on dataset and save it\n",
    "#callbacks = get_callbacks(MODEL_PATH)\n",
    "model.fit(training_generator, validation_data= validation_generator, epochs = EPOCHS, \n",
    "          callbacks = get_callbacks(MODEL_PATH, model, N_STEPS, STEPS_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a234ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}