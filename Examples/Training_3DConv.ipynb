{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aed3cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models_3D.losses import dice_loss\n",
    "from segmentation_models_3D.metrics import iou_score\n",
    "\n",
    "from GlottisNetV2.Utils.DataGenerator_3Dconv import DataGenerator\n",
    "from GlottisNetV2.Utils.data import metric_mape3D, mape_ap, mape_pp, load_video_ap\n",
    "from GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "from GlottisNetV2.Models.GlottisNetV2e_3Dconv import glottisnetV2e_3Dconv\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to training data\n",
    "vid_training = r\"Set path to training videos\" # TODO\n",
    "\n",
    "N_train = 640 # number of videos\n",
    "\n",
    "# Create video IDs for training data and save them in Pandas Dataframe\n",
    "cols = ['z', 'path']\n",
    "df_imgs_train = pd.DataFrame(columns=cols)\n",
    "df_segs_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(N_train)):\n",
    "    vpath = vid_training + \"\\\\\" + str(i) + \".mp4\"\n",
    "    \n",
    "    if os.path.exists(vpath):      \n",
    "        new_img = {'z': i, 'path': vid_training + \"/\" + str(i) + \".mp4\"}\n",
    "        new_seg = {'z': i, 'path': vid_training + \"/\" + str(i) + \"_mask.mp4\"}\n",
    "\n",
    "        df_imgs_train = df_imgs_train.append(new_img, ignore_index=True)\n",
    "        df_segs_train = df_segs_train.append(new_seg, ignore_index=True)\n",
    "\n",
    "print('Created IDs for training images.')\n",
    "\n",
    "# Save coordinates of anterior and posterior points in Pandas Dataframe\n",
    "cols = ['z', 'ap', 'pp']\n",
    "training_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(N_train)):\n",
    "    \n",
    "    # Load video path\n",
    "    path_vid = vid_training + \"/\" + str(i) + \".points\"\n",
    "    vpath = vid_training + \"//\" + str(i) + \".mp4\"\n",
    "\n",
    "    # If path exists, add video to dataframe\n",
    "    if os.path.exists(vpath):\n",
    "        ap_video = load_video_ap(path_vid, i)\n",
    "        #training_data = pd.concat([training_data, ap_video], ignore_index=True)\n",
    "        \n",
    "        training_data = training_data.append(ap_video, ignore_index=True)\n",
    "        \n",
    "\n",
    "print('Loading of anterior and posterior points finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training'''\n",
    "# Set random seed for reproducible training\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "rand = np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "\n",
    "# Set parameters\n",
    "FRAMES = 12\n",
    "BATCH_SIZE = 8\n",
    "FILTERS = 16\n",
    "LAYERS = 4\n",
    "LEARNING_RATE = 0.2e-3\n",
    "EPOCHS = 100\n",
    "TARGET_HEIGHT = 256\n",
    "TARGET_WIDTH = 128\n",
    "SHUFFLE = True\n",
    "AUGMENT = True\n",
    "MODEL_PATH = r\"Set model path\" # TODO\n",
    "STEPS_PATH = r\"Set path where model checkpoints are saved\" # TODO\n",
    "N_STEPS = 20 # Save every #N_STEPS epoch\n",
    "RADIUS = 7.5\n",
    "\n",
    "model = glottisnetV2e_3Dconv(input_size=(FRAMES, TARGET_HEIGHT, TARGET_WIDTH, 1), filters=FILTERS, layers=LAYERS)\n",
    "\n",
    "# Hard split of training and validation data\n",
    "train_vids, val_vids, train_segs, val_segs = train_test_split(df_imgs_train, df_segs_train,\n",
    "                                                              test_size=0.1, random_state=SEED)\n",
    "\n",
    "# Create new pandas dataframe for image ids\n",
    "cols = ['z', 'path', 'id']\n",
    "train_vids_new = pd.DataFrame(columns=cols)\n",
    "val_vids_new = pd.DataFrame(columns=cols)\n",
    "train_segs_new = pd.DataFrame(columns=cols)\n",
    "val_segs_new = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Multiply number of videos for training and validation\n",
    "for i in range(len(train_vids)):\n",
    "    for j in range(10):           \n",
    "\n",
    "        nr = random.randint(FRAMES, 29) \n",
    "\n",
    "        new_img = {'z': train_vids.iloc[i]['z'] , 'path': train_vids.iloc[i]['path'], 'id': nr}\n",
    "        new_seg = {'z': train_segs.iloc[i]['z'] , 'path': train_segs.iloc[i]['path'], 'id': nr}\n",
    "\n",
    "        train_vids_new  = train_vids_new.append(new_img, ignore_index=True)\n",
    "        train_segs_new  = train_segs_new.append(new_seg, ignore_index=True)   \n",
    "            \n",
    "for i in range(len(val_vids)):\n",
    "    for j in range(10):      \n",
    "\n",
    "        nr= random.randint(FRAMES, 29)\n",
    "\n",
    "        new_img = {'z': val_vids.iloc[i]['z'] , 'path': val_vids.iloc[i]['path'], 'id': nr}\n",
    "        new_seg = {'z': val_segs.iloc[i]['z'] , 'path': val_segs.iloc[i]['path'], 'id': nr}\n",
    "\n",
    "        val_vids_new  = val_vids_new.append(new_img, ignore_index=True)\n",
    "        val_segs_new = val_segs_new.append(new_seg, ignore_index=True)\n",
    "            \n",
    "# Datagenerator --> Augmentation and Shuffle\n",
    "# Training data\n",
    "training_generator = DataGenerator(train_vids_new, train_segs_new, batch_size=BATCH_SIZE, target_height=TARGET_HEIGHT, \n",
    "                                   frame_nr=FRAMES, target_width=TARGET_WIDTH, shuffle=SHUFFLE, df_coordinates=training_data,\n",
    "                                   augment=AUGMENT, radius=RADIUS)\n",
    "\n",
    "# Validation data\n",
    "validation_generator = DataGenerator(val_vids_new, val_segs_new, target_height=TARGET_HEIGHT, frame_nr=FRAMES, \n",
    "                                     target_width=TARGET_WIDTH, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                     df_coordinates=training_data, augment=False, radius=RADIUS)\n",
    "\n",
    "# Compile model with dice_loss for segmentation, mse for prediction maps and use Adam as optimizer\n",
    "# First exit: predictions of anterior and posterior points (2 channels)\n",
    "# Second exit: Segmentations\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              metrics={'seg': ['acc', iou_score],\n",
    "                       'ap_pred': ['acc', metric_mape3D, mape_ap, mape_pp]},\n",
    "              loss={'ap_pred': 'mse', 'seg': dice_loss},\n",
    "              run_eagerly=True)\n",
    "\n",
    "# Train model on training dataset and save it\n",
    "model.fit(training_generator, validation_data=validation_generator, epochs=EPOCHS,\n",
    "        callbacks=get_callbacks(MODEL_PATH, model, N_STEPS, STEPS_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451139f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}