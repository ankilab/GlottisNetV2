{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "from GlottisNetV2.Utils.DataGeneratorV1 import DataGenerator\n",
    "from GlottisNetV2.Utils.data import load_data, MAPE_V1, mape_apV1, mape_ppV1\n",
    "from GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "from GlottisNetV2.Models.GlottisNetV1 import glottisnetV1\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2c569",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set path to the text file with the image names\n",
    "coord_train = r\"Set path to JSON-file with AP points\" #TODO\n",
    "\n",
    "# Set path to training data\n",
    "img_training = r\" Set path to training images\" # TODO\n",
    "\n",
    "N_train = 200# 55750\n",
    "\n",
    "# Create video IDs for training data and save them in Pandas Dataframe\n",
    "cols = ['z','path']\n",
    "df_imgs_train = pd.DataFrame(columns= cols)\n",
    "df_segs_train = pd.DataFrame(columns =cols)\n",
    "\n",
    "for i in tqdm(range(N_train)):\n",
    "    row_imgs = {'z' : i, 'path': img_training + \"\\\\\" + str(i) + \".png\"}\n",
    "    row_segs = {'z': i, 'path': img_training + \"\\\\\" + str(i) + '_seg.png'}\n",
    "    df_imgs_train= df_imgs_train.append(row_imgs, ignore_index = True)\n",
    "    df_segs_train= df_segs_train.append(row_segs, ignore_index = True)   \n",
    "print('Created IDs for training images.')\n",
    "\n",
    "# Save coordinates of anterior and posterior points in Pandas Dataframe\n",
    "training_data = load_data(coord_train, N_train)\n",
    "print('Loading of anterior and posterior points finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training'''\n",
    "\n",
    "# Set random seed for reproducible training\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "rand=np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "\n",
    "# Set batch size, learning rate and epochs\n",
    "BATCH_SIZE = 8 # adjust for your graphics card\n",
    "LEARNING_RATE = 0.2e-3\n",
    "EPOCHS = 22\n",
    "TARGET_HEIGHT = 512\n",
    "TARGET_WIDTH = 256\n",
    "SHUFFLE = False\n",
    "AUGMENT = True\n",
    "RETURN_MAPS = False\n",
    "FILTERS = 64\n",
    "LAYERS = 4\n",
    "MODEL_PATH = r\"Set model path\" # TODO\n",
    "STEPS_PATH = r\"Set path to model checkpoints\" 'TODO'\n",
    "N_STEPS = 5 # Save every #N_STEPS epoch\n",
    "\n",
    "model = glottisnetV1(filters = FILTERS, layers = LAYERS, input_size=(TARGET_HEIGHT, TARGET_WIDTH, 1))\n",
    "\n",
    "# Hard split of training and validation data \n",
    "train_imgs, val_imgs, train_segs, val_segs = train_test_split(df_imgs_train, df_segs_train,  test_size = 0.1, random_state = SEED)\n",
    "\n",
    "# Datagenerator --> Augmentation and Shuffle\n",
    "# Training data \n",
    "training_generator = DataGenerator(train_imgs, train_segs, batch_size = BATCH_SIZE, target_height = TARGET_HEIGHT, \\\n",
    "                                   target_width = TARGET_WIDTH, shuffle = SHUFFLE, df_coordinates = training_data, \\\n",
    "                                   augment = AUGMENT)\n",
    "\n",
    "# Validation data\n",
    "validation_generator = DataGenerator(val_imgs, val_segs, target_height = TARGET_HEIGHT, \\\n",
    "                                     target_width = TARGET_WIDTH, batch_size = BATCH_SIZE, shuffle = False, \\\n",
    "                                     df_coordinates = training_data, augment = False)  \n",
    "\n",
    "\n",
    "# Compile model with dice_loss for segmentation, mse for prediction maps and use Adam as optimizer\n",
    "# First exit: coordinates of anterior and posterior points\n",
    "# Second exit: Segmentations\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE), \n",
    "              metrics={'seg': ['acc', iou_score], 'ap_pred': ['acc', MAPE_V1, mape_apV1, mape_ppV1]},\n",
    "              loss = {'ap_pred': 'mse', 'seg': dice_loss}, run_eagerly = True)\n",
    "\n",
    "\n",
    "# Train model on dataset and save it\n",
    "#callbacks = get_callbacks(MODEL_PATH)\n",
    "model.fit(training_generator, validation_data= validation_generator, epochs = EPOCHS, \n",
    "          callbacks = get_callbacks(MODEL_PATH, model, N_STEPS, STEPS_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65b57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c561333ce4ce083a7b79995c7c3f57f7259ca8e087b2e1c89262e3bcc76369b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}