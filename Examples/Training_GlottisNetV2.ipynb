{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af4172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "from GlottisNetV2.Utils.DataGenerator import DataGenerator\n",
    "from GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp\n",
    "from GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "\n",
    "from GlottisNetV2.Models.GlottisNetV2_a import glottisnetV2_a\n",
    "from GlottisNetV2.Models.GlottisNetV2_b import glottisnetV2_b\n",
    "from GlottisNetV2.Models.GlottisNetV2_c import glottisnetV2_c\n",
    "from GlottisNetV2.Models.GlottisNetV2_d import glottisnetV2_d\n",
    "from GlottisNetV2.Models.GlottisNetV2_e import glottisnetV2_e\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16061812",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set path to the text file with coordinates of the anterior and posterior points\n",
    "coord_train = r\"Set path to JSON-file with AP points\" #cTODO\n",
    "\n",
    "# Set path to training data\n",
    "img_training = r\"Set path to training images\" # TODO\n",
    "\n",
    "N_train = 100# 55750 # number of training images\n",
    "\n",
    "# Create video IDs for training data and save them in Pandas Dataframe\n",
    "cols = ['z','path']\n",
    "df_imgs_train = pd.DataFrame(columns= cols)\n",
    "df_segs_train = pd.DataFrame(columns =cols)\n",
    "\n",
    "for i in tqdm(range(N_train)):\n",
    "    row_imgs = {'z' : [i], 'path': [img_training + \"\\\\\" + str(i) + \".png\"]}\n",
    "    row_segs = {'z': [i], 'path': [img_training + \"\\\\\" + str(i) + '_seg.png']} \n",
    "    df_imgs_train = pd.concat([df_imgs_train, pd.DataFrame(row_imgs)])\n",
    "    df_segs_train = pd.concat([df_segs_train, pd.DataFrame(row_segs)])\n",
    "\n",
    "print('Created IDs for training images.')\n",
    "\n",
    "# Save coordinates of anterior and posterior points in Pandas Dataframe\n",
    "training_data = load_data(coord_train, N_train)\n",
    "print('Loaded anterior and posterior points to dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d126d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Training'''\n",
    "# Set random seed for reproducible training\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "rand=np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "\n",
    "# Set parameters\n",
    "BATCH_SIZE = 8\n",
    "FILTERS = 16\n",
    "LAYERS= 4\n",
    "LEARNING_RATE = 0.2e-3\n",
    "EPOCHS = 30\n",
    "TARGET_HEIGHT = 512\n",
    "TARGET_WIDTH = 256\n",
    "SHUFFLE = True\n",
    "AUGMENT = True\n",
    "MODEL_PATH = r\"Set model path\" # TODO\n",
    "STEPS_PATH = r\"Set path to model checkpoints\" # TODO\n",
    "N_STEPS = 20 # Save every #N_STEPS epoch\n",
    "RADIUS = 15\n",
    "\n",
    "model = glottisnetV2_e(input_size=(TARGET_HEIGHT, TARGET_WIDTH, 1), layers=LAYERS, filters=FILTERS)\n",
    "\n",
    "# Hard split of training and validation data \n",
    "train_imgs, val_imgs, train_segs, val_segs = train_test_split(df_imgs_train, \n",
    "                                                              df_segs_train,  \n",
    "                                                              test_size = 0.1, \n",
    "                                                              random_state = SEED)\n",
    "\n",
    "# Training data --> Augmentation and Shuffle\n",
    "training_generator = DataGenerator(train_imgs, train_segs, batch_size = BATCH_SIZE, target_height = TARGET_HEIGHT, \\\n",
    "                                   target_width = TARGET_WIDTH, shuffle = SHUFFLE, df_coordinates = training_data, \\\n",
    "                                   augment = AUGMENT, radius=RADIUS)\n",
    "\n",
    "# Validation data\n",
    "validation_generator = DataGenerator(val_imgs, val_segs, target_height = TARGET_HEIGHT, \\\n",
    "                                     target_width = TARGET_WIDTH, batch_size = BATCH_SIZE, shuffle = False, \\\n",
    "                                     df_coordinates = training_data, augment = False, radius=RADIUS) \n",
    "\n",
    "# Compile model with dice_loss for segmentation, mse for prediction maps and use Adam as optimizer\n",
    "# First exit: predictions of anterior and posterior points (2 channels)\n",
    "# Second exit: Segmentations\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE), \\\n",
    "              metrics = {'seg': ['acc', iou_score],\n",
    "                         'ap_pred': ['acc', metric_mape, mape_ap, mape_pp]},\n",
    "              loss = {'ap_pred': 'mse', 'seg': dice_loss}, run_eagerly=True)\n",
    "\n",
    "# Train model on dataset and save it\n",
    "model.fit(training_generator, validation_data= validation_generator, epochs = EPOCHS, \n",
    "                    callbacks = get_callbacks(MODEL_PATH, model, N_STEPS, STEPS_PATH))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa802d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab9ad1b762d22614dfe02aceadf5b4c0b83e595e73a1a2b3522cafd6b3a0cf39"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}